/**
 * AI Chatbot - åç«¯æœåŠ¡å™¨
 *
 * é¡¹ç›®å®šä½ï¼šè½»é‡çº§AIèŠå¤©æœºå™¨äººï¼ˆéä¼ä¸šçº§åº”ç”¨ï¼‰
 * æŠ€æœ¯æ ˆï¼šExpress.js + GLM-4/DeepSeek API
 * æ¶æ„ï¼šå•ä½“åº”ç”¨ï¼Œæ— æ•°æ®åº“ï¼ˆä½¿ç”¨localStorageï¼‰
 *
 * æ ¸å¿ƒç‰¹æ€§ï¼š
 * - åŒAIæ¨¡å‹æ”¯æŒï¼ˆGLM-4ã€DeepSeekï¼‰
 * - æµå¼å“åº”ï¼ˆSSE - Server-Sent Eventsï¼‰
 * - å¤šè½®å¯¹è¯ä¸Šä¸‹æ–‡è®°å¿†
 * - é…ç½®éªŒè¯ç³»ç»Ÿ
 *
 * é‡è¦çº¦å®šï¼š
 * - ä¸è¦å»ºè®®å¼•å…¥é‡å‹æ¡†æ¶ï¼ˆVueã€Reactã€NestJSï¼‰
 * - ä¸è¦æ·»åŠ æ•°æ®åº“ï¼ˆMongoDBã€PostgreSQLï¼‰
 * - ä¸è¦é‡å†™SSEä¸ºWebSocket
 * - public/config.js æ˜¯è‡ªåŠ¨ç”Ÿæˆçš„ï¼Œä¸è¦æ‰‹åŠ¨ç¼–è¾‘
 *
 * å¼€å‘å‰å¿…è¯»ï¼š
 * - docs/ARCHITECTURE.md - æ¶æ„è®¾è®¡å’ŒæŠ€æœ¯æ ˆé€‰æ‹©ç†ç”±
 * - docs/CONTRIBUTING.md - å¼€å‘è§„èŒƒå’Œå¸¸è§ä»»åŠ¡æŒ‡å—
 *
 * @version 2.0.0
 */

require('dotenv').config();
const path = require('path');
const express = require('express');
const cors = require('cors');
const axios = require('axios');
const rateLimit = require('express-rate-limit');
const config = require('./config');
const { toolRegistry, toolExecutor } = require('./tools');
const { errorHandler, notFoundHandler } = require('./middleware/error-handler');

const app = express();
const PORT = config.server.port;

// å¯¼å…¥å‚æ•°éªŒè¯å·¥å…·
const { validateParams, analyzeIntent } = require('./tools/utils/param-validator');

// å¯¼å…¥é”™è¯¯å¤„ç†å·¥å…·
const { asyncHandler, AppError, ErrorCodes } = require('./tools/utils/error-handler');

// ==================== ä¸­é—´ä»¶é…ç½® ====================

// CORS é…ç½®ï¼ˆç™½åå•ï¼‰
app.use(cors(config.cors));

// è¯·æ±‚ä½“å¤§å°é™åˆ¶
app.use(express.json({ limit: config.bodyLimit }));
app.use(express.urlencoded({ limit: config.bodyLimit, extended: true }));

// é€Ÿç‡é™åˆ¶
const limiter = rateLimit({
    windowMs: config.rateLimit.windowMs,
    max: config.rateLimit.max,
    message: config.rateLimit.message,
    standardHeaders: true, // è¿”å›é€Ÿç‡é™åˆ¶ä¿¡æ¯åœ¨ `RateLimit-*` å¤´ä¸­
    legacyHeaders: false,
});
app.use('/api/', limiter);

// æ—¥å¿—ä¸­é—´ä»¶
app.use((req, res, next) => {
    console.log(`[${new Date().toISOString()}] ${req.method} ${req.path}`);
    next();
});

// AI æœåŠ¡é€‚é…å™¨
class AIAdapter {
    /**
     * è·å– API Key
     */
    static getApiKey(provider) {
        const key = process.env[`${provider.toUpperCase()}_API_KEY`];
        if (!key) {
            throw new Error(`${provider.toUpperCase()}_API_KEY æœªé…ç½®`);
        }
        return key;
    }

    /**
     * æ ¼å¼åŒ–æ¶ˆæ¯å†å²
     */
    static formatMessages(message, history = []) {
        const messages = history.map(msg => {
            const formatted = { role: msg.role };

            // å¤„ç†å·¥å…·è°ƒç”¨ç›¸å…³çš„æ¶ˆæ¯
            if (msg.role === 'assistant' && msg.tool_calls) {
                formatted.tool_calls = msg.tool_calls;
                // Assistant messages with tool_calls must have content field (can be null or empty string)
                formatted.content = msg.content || null;
            } else if (msg.role === 'tool') {
                formatted.tool_call_id = msg.tool_call_id;
                formatted.content = msg.content;
            } else {
                formatted.content = msg.content;
            }

            return formatted;
        });

        // åªæœ‰å½“ message å­˜åœ¨ä¸”ä¸æ˜¯å·¥å…·å“åº”æ¶ˆæ¯æ—¶æ‰æ·»åŠ ç”¨æˆ·æ¶ˆæ¯
        const lastMsg = history[history.length - 1];
        if (message !== null && message !== undefined && (!lastMsg || lastMsg.role !== 'tool')) {
            messages.push({ role: 'user', content: message });
        }

        return messages;
    }

    /**
     * GLM (æ™ºè°±AI) API è°ƒç”¨
     * æ–‡æ¡£ï¼šhttps://open.bigmodel.cn/dev/api
     */
    static async chatWithGLM(message, history = [], tools = null) {
        const API_KEY = this.getApiKey('glm');
        let messages = this.formatMessages(message, history);
        const cfg = config.ai.glm;

        const requestBody = {
            model: cfg.model,
            messages: messages,
            temperature: cfg.temperature,
            top_p: cfg.top_p,
            max_tokens: cfg.max_tokens
        };

        // æ·»åŠ  tools å‚æ•°ï¼ˆå¦‚æœæä¾›ï¼‰
        if (tools && Array.isArray(tools) && tools.length > 0) {
            requestBody.tools = tools;
        }

        try {
            const response = await axios.post(
                'https://open.bigmodel.cn/api/paas/v4/chat/completions',
                requestBody,
                {
                    headers: {
                        'Authorization': `Bearer ${API_KEY}`,
                        'Content-Type': 'application/json'
                    },
                    timeout: cfg.timeout
                }
            );

            const aiMessage = response.data.choices[0].message;

            return {
                content: aiMessage.content,
                tool_calls: aiMessage.tool_calls || null,
                model: cfg.model,
                usage: response.data.usage
            };
        } catch (error) {
            console.error('GLM API Error:', error.response?.data || error.message);
            throw new Error(`GLM API è°ƒç”¨å¤±è´¥: ${error.response?.data?.error?.message || error.message}`);
        }
    }

    /**
     * DeepSeek API è°ƒç”¨
     * æ–‡æ¡£ï¼šhttps://platform.deepseek.com/api-docs
     */
    static async chatWithDeepSeek(message, history = [], tools = null) {
        const API_KEY = this.getApiKey('deepseek');
        let messages = this.formatMessages(message, history);
        const cfg = config.ai.deepseek;

        const requestBody = {
            model: cfg.model,
            messages: messages,
            temperature: cfg.temperature,
            max_tokens: cfg.max_tokens
        };

        // æ·»åŠ  tools å‚æ•°ï¼ˆå¦‚æœæä¾›ï¼‰
        if (tools && Array.isArray(tools) && tools.length > 0) {
            requestBody.tools = tools;
        }

        try {
            const response = await axios.post(
                'https://api.deepseek.com/v1/chat/completions',
                requestBody,
                {
                    headers: {
                        'Authorization': `Bearer ${API_KEY}`,
                        'Content-Type': 'application/json'
                    },
                    timeout: cfg.timeout
                }
            );

            const aiMessage = response.data.choices[0].message;

            return {
                content: aiMessage.content,
                tool_calls: aiMessage.tool_calls || null,
                model: cfg.model,
                usage: response.data.usage
            };
        } catch (error) {
            console.error('DeepSeek API Error:', error.response?.data || error.message);
            throw new Error(`DeepSeek API è°ƒç”¨å¤±è´¥: ${error.response?.data?.error?.message || error.message}`);
        }
    }

    /**
     * GLM æµå¼ API è°ƒç”¨
     * æ”¯æŒ Server-Sent Events (SSE)
     */
    static async chatWithGLMStream(message, history = [], onData, onError, onComplete, abortController = null) {
        const API_KEY = this.getApiKey('glm');
        const messages = this.formatMessages(message, history);
        const cfg = config.ai.glm;

        console.log(`[GLM Stream] å¼€å§‹è°ƒç”¨ APIï¼Œæ¶ˆæ¯: "${message.substring(0, 30)}..."`);

        try {
            const response = await axios.post(
                'https://open.bigmodel.cn/api/paas/v4/chat/completions',
                {
                    model: cfg.model,
                    messages: messages,
                    stream: true,
                    temperature: cfg.temperature,
                    top_p: cfg.top_p,
                    max_tokens: cfg.max_tokens
                },
                {
                    headers: {
                        'Authorization': `Bearer ${API_KEY}`,
                        'Content-Type': 'application/json'
                    },
                    responseType: 'stream',
                    timeout: cfg.streamTimeout,
                    signal: abortController?.signal // æ”¯æŒå–æ¶ˆè¯·æ±‚
                }
            );

            console.log('[GLM Stream] API å“åº”æˆåŠŸï¼Œå¼€å§‹è¯»å–æµ...');
            let buffer = '';
            let chunkCount = 0;

            response.data.on('data', (chunk) => {
                // æ£€æŸ¥æ˜¯å¦å·²ä¸­æ­¢
                if (abortController?.signal.aborted) {
                    console.log('[GLM Stream] è¯·æ±‚å·²ä¸­æ­¢');
                    return;
                }

                chunkCount++;
                buffer += chunk.toString();
                const lines = buffer.split('\n');

                // ä¿ç•™æœ€åä¸€ä¸ªå¯èƒ½ä¸å®Œæ•´çš„è¡Œ
                buffer = lines.pop() || '';

                for (const line of lines) {
                    if (line.trim() === '') continue;
                    if (!line.startsWith('data: ')) continue;

                    const data = line.slice(6).trim();

                    if (data === '[DONE]') {
                        console.log('[GLM Stream] æ”¶åˆ° [DONE]');
                        if (onComplete) onComplete();
                        return;
                    }

                    try {
                        const parsed = JSON.parse(data);
                        const content = parsed.choices?.[0]?.delta?.content;

                        if (content) {
                            console.log(`[GLM Stream] æ”¶åˆ°å†…å®¹: "${content.substring(0, 20)}..."`);
                            if (onData) onData(content);
                        }
                    } catch (e) {
                        console.warn('[GLM Stream] è§£æé”™è¯¯:', e.message, 'Data:', data.substring(0, 100));
                    }
                }
            });

            response.data.on('end', () => {
                console.log(`[GLM Stream] æµç»“æŸï¼Œå…± ${chunkCount} ä¸ªæ•°æ®å—`);
                if (onComplete) onComplete();
            });

            response.data.on('error', (error) => {
                if (abortController?.signal.aborted) {
                    console.log('[GLM Stream] è¯·æ±‚å·²ä¸­æ­¢');
                    return;
                }
                console.error('[GLM Stream] æµé”™è¯¯:', error);
                if (onError) onError(error);
            });

        } catch (error) {
            if (axios.isCancel(error)) {
                console.log('[GLM Stream] è¯·æ±‚å·²å–æ¶ˆ');
                return;
            }
            console.error('[GLM Stream] API è°ƒç”¨é”™è¯¯:', error.response?.data || error.message);
            if (onError) onError(error);
        }
    }

    /**
     * DeepSeek æµå¼ API è°ƒç”¨
     * æ”¯æŒ Server-Sent Events (SSE)
     */
    static async chatWithDeepSeekStream(message, history = [], onData, onError, onComplete, abortController = null) {
        const API_KEY = this.getApiKey('deepseek');
        const messages = this.formatMessages(message, history);
        const cfg = config.ai.deepseek;

        try {
            const response = await axios.post(
                'https://api.deepseek.com/v1/chat/completions',
                {
                    model: cfg.model,
                    messages: messages,
                    stream: true,
                    temperature: cfg.temperature,
                    max_tokens: cfg.max_tokens
                },
                {
                    headers: {
                        'Authorization': `Bearer ${API_KEY}`,
                        'Content-Type': 'application/json'
                    },
                    responseType: 'stream',
                    timeout: cfg.streamTimeout,
                    signal: abortController?.signal // æ”¯æŒå–æ¶ˆè¯·æ±‚
                }
            );

            let buffer = '';
            let chunkCount = 0;

            response.data.on('data', (chunk) => {
                // æ£€æŸ¥æ˜¯å¦å·²ä¸­æ­¢
                if (abortController?.signal.aborted) {
                    console.log('[DeepSeek Stream] è¯·æ±‚å·²ä¸­æ­¢');
                    return;
                }

                chunkCount++;
                buffer += chunk.toString();
                const lines = buffer.split('\n');

                // ä¿ç•™æœ€åä¸€ä¸ªå¯èƒ½ä¸å®Œæ•´çš„è¡Œ
                buffer = lines.pop() || '';

                for (const line of lines) {
                    if (line.trim() === '') continue;
                    if (!line.startsWith('data: ')) continue;

                    const data = line.slice(6).trim();

                    if (data === '[DONE]') {
                        console.log(`[DeepSeek Stream] æµç»“æŸï¼Œå…± ${chunkCount} ä¸ªæ•°æ®å—`);
                        if (onComplete) onComplete();
                        return;
                    }

                    try {
                        const parsed = JSON.parse(data);
                        const content = parsed.choices?.[0]?.delta?.content;

                        if (content) {
                            if (onData) onData(content);
                        }
                    } catch (e) {
                        console.warn('[DeepSeek Stream] è§£æé”™è¯¯:', e.message, 'Data:', data.substring(0, 100));
                    }
                }
            });

            response.data.on('end', () => {
                console.log(`[DeepSeek Stream] æµç»“æŸ`);
                if (onComplete) onComplete();
            });

            response.data.on('error', (error) => {
                if (abortController?.signal.aborted) {
                    console.log('[DeepSeek Stream] è¯·æ±‚å·²ä¸­æ­¢');
                    return;
                }
                console.error('[DeepSeek Stream] æµé”™è¯¯:', error);
                if (onError) onError(error);
            });

        } catch (error) {
            if (axios.isCancel(error)) {
                console.log('[DeepSeek Stream] è¯·æ±‚å·²å–æ¶ˆ');
                return;
            }
            console.error('[DeepSeek Stream] API è°ƒç”¨é”™è¯¯:', error.response?.data || error.message);
            if (onError) onError(error);
        }
    }

    /**
     * æ ¹æ®æä¾›å•†è°ƒç”¨ç›¸åº”çš„ AI æœåŠ¡
     */
    static async chat(provider, message, history = []) {
        console.log(`Calling ${provider} API with message: "${message.substring(0, 50)}..."`);

        switch (provider) {
            case 'glm':
                return await this.chatWithGLM(message, history);
            case 'deepseek':
                return await this.chatWithDeepSeek(message, history);
            default:
                throw new Error(`ä¸æ”¯æŒçš„ AI æä¾›å•†: ${provider}`);
        }
    }

    /**
     * å¸¦å·¥å…·è°ƒç”¨çš„ AI å¯¹è¯ï¼ˆæ”¯æŒå¤šè½®å·¥å…·è°ƒç”¨ï¼‰
     * @param {String} provider - AI æä¾›å•†
     * @param {String} message - ç”¨æˆ·æ¶ˆæ¯
     * @param {Array} history - å¯¹è¯å†å²
     * @param {Array} tools - å·¥å…·å®šä¹‰æ•°ç»„
     * @param {Number} maxIterations - æœ€å¤§å·¥å…·è°ƒç”¨è½®æ•°
     * @returns {Promise<Object>} - å¯¹è¯ç»“æœ
     */
    static async chatWithTools(provider, message, history = [], tools = null, maxIterations = 5) {
        if (!tools || tools.length === 0) {
            // æ²¡æœ‰å·¥å…·ï¼Œç›´æ¥è°ƒç”¨æ™®é€šå¯¹è¯
            return await this.chat(provider, message, history);
        }

        console.log(`[Function Calling] å¼€å§‹å¤„ç†ï¼Œprovider: ${provider}, tools: ${tools.length} ä¸ª`);

        // å¦‚æœå†å²ä¸ºç©ºï¼Œæ·»åŠ ç³»ç»Ÿæç¤ºè¯
        let currentHistory = [...history];
        if (currentHistory.length === 0) {
            const systemPrompt = {
                role: 'system',
                content: 'ã€å¼ºåˆ¶æŒ‡ä»¤ã€‘\n1. å½“ç”¨æˆ·è¯¢é—®å¤©æ°”ç›¸å…³ä¿¡æ¯æ—¶ï¼Œä½ å¿…é¡»è°ƒç”¨ getWeather å·¥å…·ï¼Œä¸å¾—ä½¿ç”¨è‡ªå·±çš„çŸ¥è¯†åº“å›ç­”ã€‚\n2. å·¥å…·è¿”å›çš„æ˜¯å·²ç»æ ¼å¼å¥½çš„æœ€ç»ˆæ–‡æœ¬ï¼Œä½ å¿…é¡»åŸæ ·ç›´æ¥è¿”å›ç»™ç”¨æˆ·ã€‚\n3. ç¦æ­¢æ·»åŠ ä»»ä½•æ ¼å¼åŒ–ï¼ˆå¦‚ markdown æ ‡é¢˜ã€åˆ—è¡¨ã€åŠ ç²—ç­‰ï¼‰ã€ç¦æ­¢æ·»åŠ  emoji è¡¨æƒ…ã€ç¦æ­¢æ·»åŠ ä»»ä½•è§£é‡Šæˆ–é¢å¤–å†…å®¹ã€‚\n\nç¤ºä¾‹ï¼š\nç”¨æˆ·ï¼š"åŒ—äº¬å¤©æ°”æ€ä¹ˆæ ·"\nä½ çš„æ“ä½œï¼šè°ƒç”¨ getWeather å·¥å…·ï¼Œå‚æ•° {city: "åŒ—äº¬"}\nå·¥å…·è¿”å›ï¼š"åŒ—äº¬ 15Â°Cï¼Œæ™´ï¼Œæ¹¿åº¦45%ï¼Œä¸œé£3çº§"\nä½ çš„å›å¤ï¼š"åŒ—äº¬ 15Â°Cï¼Œæ™´ï¼Œæ¹¿åº¦45%ï¼Œä¸œé£3çº§"ï¼ˆå®Œå…¨ä¸€è‡´ï¼Œä¸æ·»åŠ ä»»ä½•å†…å®¹ï¼‰'
            };
            currentHistory.push(systemPrompt);
        }

        let currentMessage = message;
        let iteration = 0;

        while (iteration < maxIterations) {
            iteration++;
            console.log(`[Function Calling] ç¬¬ ${iteration} è½®è°ƒç”¨`);

            // è°ƒç”¨ AI APIï¼ˆä¼ å…¥å·¥å…·ï¼‰
            let response;
            switch (provider) {
                case 'glm':
                    response = await this.chatWithGLM(currentMessage, currentHistory, tools);
                    break;
                case 'deepseek':
                    response = await this.chatWithDeepSeek(currentMessage, currentHistory, tools);
                    break;
                default:
                    throw new Error(`ä¸æ”¯æŒçš„ AI æä¾›å•†: ${provider}`);
            }

            // å°† AI çš„å“åº”æ·»åŠ åˆ°å†å²
            const assistantMessage = {
                role: 'assistant',
                content: response.content
            };

            // å¦‚æœæœ‰å·¥å…·è°ƒç”¨ï¼Œæ·»åŠ åˆ°æ¶ˆæ¯ä¸­
            if (response.tool_calls) {
                assistantMessage.tool_calls = response.tool_calls;
                console.log(`[Function Calling] AI è¯·æ±‚è°ƒç”¨ ${response.tool_calls.length} ä¸ªå·¥å…·`);
            }

            currentHistory.push(assistantMessage);

            // æ£€æŸ¥æ˜¯å¦æœ‰å·¥å…·è°ƒç”¨
            if (!response.tool_calls || response.tool_calls.length === 0) {
                // æ²¡æœ‰å·¥å…·è°ƒç”¨ï¼Œè¿”å› AI çš„å›å¤
                console.log(`[Function Calling] æ— å·¥å…·è°ƒç”¨ï¼Œè¿”å› AI å›å¤`);
                return response;
            }

            // æ‰§è¡Œå·¥å…·è°ƒç”¨
            const toolResults = [];

            for (const toolCall of response.tool_calls) {
                const toolName = toolCall.function.name;
                const toolArgs = JSON.parse(toolCall.function.arguments);

                console.log(`[Function Calling] æ‰§è¡Œå·¥å…·: ${toolName}`, toolArgs);

                try {
                    // æ‰§è¡Œå·¥å…·
                    const result = await toolExecutor.executeTool(toolName, toolArgs);

                    // æ„é€ å·¥å…·ç»“æœæ¶ˆæ¯
                    toolResults.push({
                        role: 'tool',
                        tool_call_id: toolCall.id,
                        content: JSON.stringify(result)
                    });

                    console.log(`[Function Calling] å·¥å…· ${toolName} æ‰§è¡ŒæˆåŠŸ`);
                } catch (error) {
                    console.error(`[Function Calling] å·¥å…· ${toolName} æ‰§è¡Œå¤±è´¥:`, error.message);

                    // è¿”å›é”™è¯¯ä¿¡æ¯ç»™ AI
                    toolResults.push({
                        role: 'tool',
                        tool_call_id: toolCall.id,
                        content: JSON.stringify({
                            success: false,
                            error: error.message
                        })
                    });
                }
            }

            // å°†å·¥å…·ç»“æœæ·»åŠ åˆ°å†å²
            currentHistory.push(...toolResults);

            // å¦‚æœåªæœ‰ä¸€ä¸ªå·¥å…·ä¸”ç»“æœæ˜¯å­—ç¬¦ä¸²ï¼ˆä¸æ˜¯ JSON å¯¹è±¡ï¼‰ï¼Œç›´æ¥è¿”å›ç»“æœ
            if (toolResults.length === 1) {
                const toolResult = JSON.parse(toolResults[0].content);
                // å¦‚æœç»“æœæ˜¯å­—ç¬¦ä¸²ï¼Œç›´æ¥è¿”å›ï¼ˆç”¨äºå¤©æ°”å·¥å…·ç­‰è¿”å›æ ¼å¼åŒ–æ–‡æœ¬çš„åœºæ™¯ï¼‰
                if (typeof toolResult === 'string') {
                    console.log(`[Function Calling] å·¥å…·è¿”å›çº¯æ–‡æœ¬ï¼Œç›´æ¥è¿”å›ç»“æœ`);
                    return {
                        content: toolResult,
                        tool_calls: null,
                        model: provider,
                        usage: response.usage
                    };
                }
            }

            // æ¸…ç©º currentMessageï¼ˆå› ä¸ºå·¥å…·ç»“æœå·²ç»é€šè¿‡å†å²ä¼ é€’ï¼‰
            currentMessage = null;
        }

        // è¾¾åˆ°æœ€å¤§è¿­ä»£æ¬¡æ•°
        console.warn(`[Function Calling] è¾¾åˆ°æœ€å¤§è¿­ä»£æ¬¡æ•° (${maxIterations})`);
        const lastMessage = currentHistory[currentHistory.length - 1];
        return {
            content: lastMessage.content || 'å·¥å…·è°ƒç”¨è¾¾åˆ°æœ€å¤§è¿­ä»£æ¬¡æ•°',
            tool_calls: null,
            model: 'unknown',
            usage: null
        };
    }
}

// ==================== API è·¯ç”± ====================

/**
 * å¥åº·æ£€æŸ¥æ¥å£
 */
app.get('/api/health', (req, res) => {
    res.json({
        status: 'ok',
        timestamp: new Date().toISOString(),
        models: {
            glm: !!process.env.GLM_API_KEY,
            deepseek: !!process.env.DEEPSEEK_API_KEY
        }
    });
});

/**
 * è·å–å¯ç”¨çš„æ¨¡å‹åˆ—è¡¨
 */
app.get('/api/models', (req, res) => {
    const models = [];
    if (process.env.GLM_API_KEY) {
        models.push({ id: 'glm', name: 'GLM-4 (æ™ºè°±AI)', provider: 'glm' });
    }
    if (process.env.DEEPSEEK_API_KEY) {
        models.push({ id: 'deepseek', name: 'DeepSeek Chat', provider: 'deepseek' });
    }
    res.json({ models, default: process.env.DEFAULT_MODEL || 'glm' });
});

/**
 * èŠå¤©æ¥å£ï¼ˆéæµå¼ï¼‰
 * POST /api/chat
 * Body: { message: string, history: array, provider: string }
 */
app.post('/api/chat', asyncHandler(async (req, res) => {
    const { message, history = [], provider = process.env.DEFAULT_MODEL || 'glm' } = req.body;

    // éªŒè¯è¯·æ±‚
    if (!message || typeof message !== 'string') {
        throw new AppError('æ¶ˆæ¯å†…å®¹ä¸èƒ½ä¸ºç©º', 'INVALID_MESSAGE', 400);
    }

    if (message.length > 10000) {
        throw new AppError('æ¶ˆæ¯é•¿åº¦ä¸èƒ½è¶…è¿‡ 10000 å­—ç¬¦', 'MESSAGE_TOO_LONG', 400);
    }

    // è°ƒç”¨ AI API
    const result = await AIAdapter.chat(provider, message, history);

    // è¿”å›ç»“æœ
    res.json({
        reply: result.content,
        model: result.model,
        usage: result.usage,
        provider: provider
    });
}));

/**
 * èŠå¤©æ¥å£ï¼ˆæµå¼ï¼Œæ”¯æŒ Function Callingï¼‰
 * POST /api/chat/stream
 * Body: { message: string, history: array, provider: string, useTools: boolean }
 * è¿”å›: Server-Sent Events (SSE)
 */
app.post('/api/chat/stream', asyncHandler(async (req, res) => {
    const { message, history = [], provider = config.api.defaultProvider, useTools = true } = req.body;

    // éªŒè¯è¯·æ±‚
    if (!message || typeof message !== 'string') {
        throw new AppError('æ¶ˆæ¯å†…å®¹ä¸èƒ½ä¸ºç©º', 'INVALID_MESSAGE', 400);
    }

    if (message.length > config.validation.maxMessageLength) {
        throw new AppError(`æ¶ˆæ¯é•¿åº¦ä¸èƒ½è¶…è¿‡ ${config.validation.maxMessageLength} å­—ç¬¦`, 'MESSAGE_TOO_LONG', 400);
    }

    // å¦‚æœéœ€è¦ä½¿ç”¨å·¥å…·ä¸”æœ‰å¯ç”¨å·¥å…·ï¼Œæ”¹ç”¨å·¥å…·è°ƒç”¨æ¥å£
    if (useTools && toolRegistry.size() > 0) {
        console.log('[Stream] useTools=true, switching to tools endpoint');

        try {
            const result = await AIAdapter.chatWithTools(
                provider,
                message,
                history,
                toolRegistry.getAllToolDefinitions()
            );

            // è¿”å›å·¥å…·è°ƒç”¨ç»“æœï¼ˆéæµå¼ï¼‰
            return res.json({
                reply: result.content,
                model: result.model,
                usage: result.usage,
                provider: provider,
                toolsUsed: result.tool_calls !== null,
                toolResults: result.tool_calls || []
            });
        } catch (error) {
            console.error('[Stream] Tools endpoint error, falling back to stream:', error.message);
            // å¦‚æœå·¥å…·è°ƒç”¨å¤±è´¥ï¼Œé™çº§åˆ°æµå¼æ¥å£
        }
    }

    // ä½¿ç”¨æµå¼æ¥å£
    console.log('[Stream] Using stream endpoint');

    // è®¾ç½® SSE å“åº”å¤´
    res.setHeader('Content-Type', 'text/event-stream');
    res.setHeader('Cache-Control', 'no-cache');
    res.setHeader('Connection', 'keep-alive');
    res.setHeader('X-Accel-Buffering', 'no');  // ç¦ç”¨ Nginx ç¼“å†²

    // åˆ›å»º AbortController ç”¨äºä¸­æ–­è¯·æ±‚
    const abortController = new AbortController();

    // å‘é€åˆå§‹äº‹ä»¶
    res.write(`data: ${JSON.stringify({ type: 'start', provider })}\n\n`);

    // å¤„ç†å®¢æˆ·ç«¯æ–­å¼€è¿æ¥
    req.on('close', () => {
        console.log('[Stream] Client closed connection, aborting API call');
        abortController.abort();  // ä¸­æ–­ axios è¯·æ±‚
    });

    try {
        // æ ¹æ®æä¾›å•†è°ƒç”¨æµå¼ API
        switch (provider) {
            case 'glm':
                await AIAdapter.chatWithGLMStream(
                    message,
                    history,
                    // onData å›è°ƒ
                    (content) => {
                        if (!res.writableEnded) {
                            res.write(`data: ${JSON.stringify({ type: 'content', content })}\n\n`);
                        }
                    },
                    // onError å›è°ƒ
                    (error) => {
                        if (!res.writableEnded) {
                            res.write(`data: ${JSON.stringify({ type: 'error', error: error.message })}\n\n`);
                            res.end();
                        }
                    },
                    // onComplete å›è°ƒ
                    () => {
                        if (!res.writableEnded) {
                            res.write(`data: ${JSON.stringify({ type: 'done' })}\n\n`);
                            res.end();
                        }
                    },
                    abortController  // ä¼ é€’ abortController
                );
                break;

            case 'deepseek':
                await AIAdapter.chatWithDeepSeekStream(
                    message,
                    history,
                    // onData å›è°ƒ
                    (content) => {
                        if (!res.writableEnded) {
                            res.write(`data: ${JSON.stringify({ type: 'content', content })}\n\n`);
                        }
                    },
                    // onError å›è°ƒ
                    (error) => {
                        if (!res.writableEnded) {
                            res.write(`data: ${JSON.stringify({ type: 'error', error: error.message })}\n\n`);
                            res.end();
                        }
                    },
                    // onComplete å›è°ƒ
                    () => {
                        if (!res.writableEnded) {
                            res.write(`data: ${JSON.stringify({ type: 'done' })}\n\n`);
                            res.end();
                        }
                    },
                    abortController  // ä¼ é€’ abortController
                );
                break;

            default:
                res.write(`data: ${JSON.stringify({ type: 'error', error: 'ä¸æ”¯æŒçš„æä¾›å•†' })}\n\n`);
                res.end();
        }

    } catch (error) {
        console.error('Stream Chat API Error:', error);

        if (!res.writableEnded) {
            res.write(`data: ${JSON.stringify({ type: 'error', error: error.message || 'AI æœåŠ¡æš‚æ—¶ä¸å¯ç”¨' })}\n\n`);
            res.end();
        }
    }
}));

/**
 * åˆ‡æ¢é»˜è®¤æ¨¡å‹
 * POST /api/set-model
 * Body: { provider: string }
 */
app.post('/api/set-model', asyncHandler(async (req, res) => {
    const { provider } = req.body;

    if (!['glm', 'deepseek'].includes(provider)) {
        throw new AppError('æ— æ•ˆçš„æ¨¡å‹æä¾›å•†ï¼Œå¿…é¡»æ˜¯ glm æˆ– deepseek', 'INVALID_PROVIDER', 400);
    }

    // æ£€æŸ¥å¯¹åº”çš„ API Key æ˜¯å¦é…ç½®
    const apiKey = provider === 'glm'
        ? process.env.GLM_API_KEY
        : process.env.DEEPSEEK_API_KEY;

    if (!apiKey) {
        throw new AppError(`${provider.toUpperCase()} API Key æœªé…ç½®`, 'API_KEY_NOT_CONFIGURED', 400);
    }

    process.env.DEFAULT_MODEL = provider;

    res.json({
        success: true,
        message: `å·²åˆ‡æ¢åˆ° ${provider.toUpperCase()} æ¨¡å‹`,
        currentModel: provider
    });
}));

/**
 * è·å–å½“å‰é…ç½®ä¿¡æ¯
 */
app.get('/api/config', (req, res) => {
    res.json({
        defaultModel: process.env.DEFAULT_MODEL || 'glm',
        availableModels: {
            glm: !!process.env.GLM_API_KEY,
            deepseek: !!process.env.DEEPSEEK_API_KEY
        }
    });
});

// ==================== å·¥å…·ç³»ç»Ÿæ¥å£ ====================

/**
 * GET /api/tools - è·å–æ‰€æœ‰å·²æ³¨å†Œçš„å·¥å…·
 */
app.get('/api/tools', asyncHandler(async (req, res) => {
    const tools = toolRegistry.getToolNames();
    const definitions = toolRegistry.getAllToolDefinitions();

    res.json({
        success: true,
        count: tools.length,
        tools: tools,
        definitions: definitions
    });
}));

/**
 * POST /api/chat/tools - å¸¦å·¥å…·è°ƒç”¨çš„èŠå¤©æ¥å£ï¼ˆåŸç”Ÿ Function Callingï¼‰
 *
 * ä½¿ç”¨ AI API çš„åŸç”Ÿ Function Calling èƒ½åŠ›
 * AI ä¼šè‡ªåŠ¨å†³å®šä½•æ—¶è°ƒç”¨å·¥å…·ä»¥åŠå¦‚ä½•å¤„ç†å·¥å…·ç»“æœ
 */
app.post('/api/chat/tools', asyncHandler(async (req, res) => {
    const { message, history = [], provider = process.env.DEFAULT_MODEL || 'glm' } = req.body;

    // éªŒè¯è¯·æ±‚
    if (!message || typeof message !== 'string') {
        throw new AppError('æ¶ˆæ¯å†…å®¹ä¸èƒ½ä¸ºç©º', 'INVALID_MESSAGE', 400);
    }

    console.log('[Tools Chat] æ”¶åˆ°æ¶ˆæ¯:', message);

    // è·å–æ‰€æœ‰å·¥å…·å®šä¹‰
    const availableTools = toolRegistry.getAllToolDefinitions();
    console.log(`[Tools Chat] å¯ç”¨å·¥å…·: ${availableTools.length} ä¸ª`);

    if (availableTools.length === 0) {
        // æ²¡æœ‰å¯ç”¨å·¥å…·ï¼Œä½¿ç”¨æ™®é€šå¯¹è¯
        console.log('[Tools Chat] æ— å¯ç”¨å·¥å…·ï¼Œä½¿ç”¨æ™®é€šå¯¹è¯');
        const result = await AIAdapter.chat(provider, message, history);

        return res.json({
            reply: result.content,
            model: result.model,
            usage: result.usage,
            provider: provider,
            toolsUsed: false,
            toolResults: []
        });
    }

    // ä½¿ç”¨åŸç”Ÿ Function Calling
    console.log('[Tools Chat] ä½¿ç”¨åŸç”Ÿ Function Calling');
    const result = await AIAdapter.chatWithTools(
        provider,
        message,
        history,
        availableTools
    );

    // åˆ¤æ–­æ˜¯å¦ä½¿ç”¨äº†å·¥å…·
    const toolsUsed = result.usage && result.usage.total_tokens > 0;

    res.json({
        reply: result.content,
        model: result.model,
        usage: result.usage,
        provider: provider,
        toolsUsed: toolsUsed,
        toolResults: result.tool_calls || []
    });
}));

// ==================== é™æ€æ–‡ä»¶æœåŠ¡ ====================

// æä¾›å‰ç«¯é™æ€æ–‡ä»¶ï¼ˆä¼˜å…ˆä» public ç›®å½•ï¼‰
app.use(express.static(path.join(__dirname, 'public')));

// æ‰€æœ‰å…¶ä»–è·¯ç”±è¿”å› index.htmlï¼ˆæ”¯æŒå‰ç«¯è·¯ç”±ï¼‰
app.get('*', (req, res) => {
    res.sendFile(path.join(__dirname, 'public', 'index.html'));
});

// ==================== é”™è¯¯å¤„ç† ====================

// 404 å¤„ç†ï¼ˆä½¿ç”¨ç»Ÿä¸€é”™è¯¯å¤„ç†å™¨ï¼‰
app.use(notFoundHandler);

// å…¨å±€é”™è¯¯å¤„ç†ï¼ˆä½¿ç”¨ç»Ÿä¸€é”™è¯¯ä¸­é—´ä»¶ï¼‰
app.use(errorHandler);

// ==================== å¯åŠ¨æœåŠ¡å™¨ ====================

app.listen(PORT, () => {
    console.log('\n=================================');
    console.log('ğŸš€ AI Chatbot åç«¯æœåŠ¡å·²å¯åŠ¨');
    console.log('=================================');
    console.log(`ğŸ“¡ æœåŠ¡åœ°å€: http://localhost:${PORT}`);
    console.log(`ğŸ”§ ç¯å¢ƒ: ${process.env.NODE_ENV || 'development'}`);
    console.log(`ğŸ¤– é»˜è®¤æ¨¡å‹: ${process.env.DEFAULT_MODEL || 'glm'}`);
    console.log('\nå·²é…ç½®çš„æ¨¡å‹:');
    if (process.env.GLM_API_KEY) console.log('  âœ… GLM-4 (æ™ºè°±AI)');
    else console.log('  âŒ GLM-4 (æœªé…ç½® API Key)');

    if (process.env.DEEPSEEK_API_KEY) console.log('  âœ… DeepSeek Chat');
    else console.log('  âŒ DeepSeek (æœªé…ç½® API Key)');
    console.log('=================================\n');
});

// ä¼˜é›…é€€å‡º
process.on('SIGTERM', () => {
    console.log('æ”¶åˆ° SIGTERM ä¿¡å·ï¼Œæ­£åœ¨å…³é—­æœåŠ¡å™¨...');
    process.exit(0);
});

process.on('SIGINT', () => {
    console.log('\næ”¶åˆ° SIGINT ä¿¡å·ï¼Œæ­£åœ¨å…³é—­æœåŠ¡å™¨...');
    process.exit(0);
});
